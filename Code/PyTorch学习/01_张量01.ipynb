{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 张量的数据类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 导入需要的库\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 获取张量的数据类型\n",
    "torch.tensor([1.2, 3.4]).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 张量默认的数据类型 设置调整\n",
    "torch.set_default_tensor_type(torch.DoubleTensor)\n",
    "torch.tensor([1.2, 3.4]).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.dtype torch.float64\n",
      "a.long() torch.int64\n",
      "a.int() torch.int32\n",
      "a.float() torch.float32\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([1.2, 3.4])\n",
    "print(\"a.dtype\", a.dtype)\n",
    "print(\"a.long()\", a.long().dtype)\n",
    "print(\"a.int()\", a.int().dtype)\n",
    "print(\"a.float()\", a.float().dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_default_tensor_type(torch.FloatTensor)\n",
    "torch.tensor([1.2, 3.4]).dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.get_default_dtype()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 生成张量"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 基本方法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [2., 2.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.tensor([[1.0, 1.0], [2, 2]])\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 计算张量中所有元素的个数\n",
    "A.numel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.], requires_grad=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 指定张量的数据类型和是否要计算梯度\n",
    "B = torch.tensor((1,2,3), dtype=torch.float32, requires_grad=True)\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 4., 6.])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 因为张量B可计算梯度，所以可以计算 sum(B^2)的梯度\n",
    "y = B.pow(2).sum()\n",
    "y.backward()\n",
    "B.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Only Tensors of floating point and complex dtype can require gradients",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m B = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mint32\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequires_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: Only Tensors of floating point and complex dtype can require gradients"
     ]
    }
   ],
   "source": [
    "# Only Tensors of floating point and complex dtype can require gradients\n",
    "# B = torch.tensor((1,2,3), dtype=torch.int32, requires_grad=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3., 4.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = torch.Tensor([1,2,3,4])\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = torch.Tensor(2,3)\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones_like(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros_like(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2408, 0.3624, 0.7968],\n",
       "        [0.2176, 0.9197, 0.6323]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand_like(D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D.dtype torch.float32\n",
      "E.dtype torch.float32\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2.],\n",
       "        [3., 4.]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 创建一个类型相似但尺寸不同的张量\n",
    "E = [[1,2],[3,4]]\n",
    "E = D.new_tensor(E)\n",
    "print(\"D.dtype\", D.dtype)\n",
    "print(\"E.dtype\", E.dtype)\n",
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D.new_full((3,3), fill_value=1)\n",
    "D.new_zeros((3,3))\n",
    "D.new_empty((3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 利用 numpy 数组生成张量\n",
    "import numpy as np\n",
    "F = np.ones((3,3))\n",
    "Ftensor = torch.as_tensor(F)\n",
    "Ftensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.],\n",
       "        [1., 1., 1.]], dtype=torch.float64)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ftensor = torch.from_numpy(F)\n",
    "Ftensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1.],\n",
       "       [1., 1., 1.],\n",
       "       [1., 1., 1.]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ftensor.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 随机生成张量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.1115)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 指定均值和标准差生成随机数\n",
    "torch.manual_seed(123)\n",
    "A = torch.normal(mean = 0.0, std =torch.tensor(1.0))\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.1115,  0.2407, -1.1089, -0.9617])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "A = torch.normal(mean = 0.0, std =torch.arange(1, 5.0))\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.8885, 2.2407, 1.8911, 3.0383])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "A = torch.normal(mean = torch.arange(1, 5.0), std =torch.arange(1, 5.0))\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2961, 0.5166, 0.2517, 0.6886],\n",
       "        [0.0740, 0.8665, 0.1366, 0.1025],\n",
       "        [0.1841, 0.7264, 0.3153, 0.6871]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "B = torch.rand(3, 4)\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2961, 0.5166, 0.2517],\n",
       "        [0.6886, 0.0740, 0.8665]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "C = torch.ones(2,3)\n",
    "D = torch.rand_like(C)\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 8, 1, 3, 7, 4, 9, 5, 6])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(123)\n",
    "torch.randperm(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 其他生成张量的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 4, 6, 8])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(start=0, end=10, step=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.0000,  3.2500,  5.5000,  7.7500, 10.0000])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 等间格的点\n",
    "torch.linspace(start=1, end=10, steps = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.2589,  2.1135,  3.5481,  5.9566, 10.0000])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 对数间隔的点\n",
    "torch.logspace(start=0.1, end=1.0, steps=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 1.2589,  2.1135,  3.5481,  5.9566, 10.0000])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "10 ** (torch.linspace(start=0.1, end=1, steps = 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2500, 0.2500, 0.2500],\n",
       "        [0.2500, 0.2500, 0.2500],\n",
       "        [0.2500, 0.2500, 0.2500]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(3,3)\n",
    "torch.ones(3,3)\n",
    "torch.eye(3)\n",
    "torch.empty(3,3)\n",
    "torch.full((3,3), fill_value=0.25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 张量的操作"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 改变张量的尺寸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.],\n",
       "        [ 4.,  5.,  6.,  7.],\n",
       "        [ 8.,  9., 10., 11.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(12.0)\n",
    "A = A.reshape(3, 4)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.,  4.,  5.],\n",
       "        [ 6.,  7.,  8.,  9., 10., 11.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.reshape(input=A, shape=(2, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  3.,  4.,  5.],\n",
       "        [ 6.,  7.,  8.,  9., 10., 11.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.resize_(2,6)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2.],\n",
       "        [3., 4., 5.],\n",
       "        [6., 7., 8.]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 删除多余的\n",
    "B = torch.arange(10.0, 19.0).reshape(3,3)\n",
    "A.resize_as_(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 6])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## torch.unsqueeze 在指定维度上为张量增加一个维度（大小为 1）。\n",
    "A = torch.arange(12.0).reshape(2,6)\n",
    "B = torch.unsqueeze(A, dim = 0) # dim=0, 表示在第 0 维（最外层）增加一个维度。\n",
    "B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C.shape torch.Size([1, 2, 6, 1])\n",
      "D.shape torch.Size([2, 6])\n",
      "E.shape torch.Size([2, 6, 1])\n"
     ]
    }
   ],
   "source": [
    "C = B.unsqueeze(dim=3)\n",
    "print(\"C.shape\", C.shape)\n",
    "D = torch.squeeze(C) # 移除所有维度为1的维度\n",
    "print(\"D.shape\", D.shape)\n",
    "E = torch.squeeze(C, dim=0)# 移除指定dim层 维度为1的维度\n",
    "print(\"E.shape\", E.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [0, 1, 2],\n",
       "        [0, 1, 2]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# expand方法拓展张量\n",
    "A = torch.arange(3)\n",
    "B = A.expand(3, -1)\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2],\n",
       "        [0, 1, 2]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 使用 expand_as 方法拓展张量\n",
    "C = torch.arange(6).reshape(2,3)\n",
    "B = A.expand_as(C)\n",
    "B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1, 2],\n",
      "        [0, 1, 2]])\n",
      "torch.Size([2, 3])\n",
      "tensor([[[0, 1, 2, 0, 1, 2],\n",
      "         [0, 1, 2, 0, 1, 2],\n",
      "         [0, 1, 2, 0, 1, 2],\n",
      "         [0, 1, 2, 0, 1, 2]]])\n",
      "torch.Size([1, 4, 6])\n"
     ]
    }
   ],
   "source": [
    "print(B)\n",
    "print(B.shape)\n",
    "D = B.repeat(1,2,2) \n",
    "# 第 0 维重复 1 次 \n",
    "# 第 1 维重复 2 次\n",
    "# 第 2 维重复 2 次\n",
    "print(D)\n",
    "print(D.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 获取张量中的元素"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 4,  5,  6,  7],\n",
       "         [ 8,  9, 10, 11]]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(12).reshape(1,3,4)\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  1,  2,  3],\n",
       "        [ 4,  5,  6,  7],\n",
       "        [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 2, 3],\n",
       "        [4, 5, 6, 7]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 获取第0维度下的矩阵前两行元素\n",
    "A[0, 0:2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8,  9, 10])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取0维度下的矩阵， 最后一行的，-4到-1的列\n",
    "A[0,-1,-4:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0, -1, -2, -3],\n",
       "         [-4, -5,  6,  7],\n",
       "         [ 8,  9, 10, 11]]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 根据条件筛选\n",
    "B= -A\n",
    "torch.where(A>5, A, B)  # where condition if A else B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6,  7,  8,  9, 10, 11])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取A中大于5的元素\n",
    "A[A>5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0,  1,  2,  3],\n",
      "         [ 4,  5,  6,  7],\n",
      "         [ 8,  9, 10, 11]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(11)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取其中的 0维度 / 第二行 / 第三列\n",
    "print(A)\n",
    "A[0,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  0,  0,  0],\n",
       "         [ 4,  5,  0,  0],\n",
       "         [ 8,  9, 10,  0]]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 获取矩阵张量的下三角部分\n",
    "torch.tril(A, diagonal=0, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  0,  0],\n",
       "         [ 4,  5,  6,  0],\n",
       "         [ 8,  9, 10, 11]]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# diagonal 参数控制考虑对角线\n",
    "torch.tril(A, diagonal=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0,  1,  2,  3],\n",
       "         [ 0,  5,  6,  7],\n",
       "         [ 0,  0, 10, 11]]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# diagonal 上三角部分\n",
    "torch.triu(A, diagonal=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  1,  2,  3],\n",
      "        [ 4,  5,  6,  7],\n",
      "        [ 8,  9, 10, 11]])\n",
      "tensor([ 0,  5, 10])\n",
      "tensor([ 1,  6, 11])\n"
     ]
    }
   ],
   "source": [
    "C = A.reshape(3,4)\n",
    "print(C)\n",
    "print(torch.diag(C, diagonal=0))\n",
    "print(torch.diag(C, diagonal=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0],\n",
       "        [0, 2, 0],\n",
       "        [0, 0, 3]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 提供对角线元素生成矩阵张量\n",
    "torch.diag(torch.tensor([1,2,3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 拼接和拆分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.],\n",
       "        [ 3.,  4.,  5.],\n",
       "        [ 0.,  2.,  4.],\n",
       "        [ 6.,  8., 10.]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(6.0).reshape(2,3)\n",
    "B = torch.linspace(0,10,6).reshape(2,3)\n",
    "#  在0维度拼接张量\n",
    "C = torch.cat((A,B), dim=0)\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  2.,  0.,  2.,  4.],\n",
       "        [ 3.,  4.,  5.,  6.,  8., 10.]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = torch.cat((A,B), dim=1)\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.,  0.,  1.,  2.,  0.,  2.,  4.],\n",
       "        [ 4.,  3.,  4.,  5.,  6.,  8., 10.]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "E = torch.cat((A[:,1:2], A, B), dim=1)\n",
    "E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  1.,  2.],\n",
      "         [ 3.,  4.,  5.]],\n",
      "\n",
      "        [[ 0.,  2.,  4.],\n",
      "         [ 6.,  8., 10.]]])\n",
      "torch.Size([2, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "F = torch.stack((A,B), dim=0)\n",
    "print(F)\n",
    "print(F.shape)\n",
    "# 2个2*3的矩阵组合在一起"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.,  0.],\n",
      "         [ 1.,  2.],\n",
      "         [ 2.,  4.]],\n",
      "\n",
      "        [[ 3.,  6.],\n",
      "         [ 4.,  8.],\n",
      "         [ 5., 10.]]])\n",
      "torch.Size([2, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "G = torch.stack((A,B),dim=2)\n",
    "print(G)\n",
    "print(G.shape)\n",
    "# 2个3*2的矩阵组合在一起"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 0., 1., 2., 0., 2., 4.]]),\n",
       " tensor([[ 4.,  3.,  4.,  5.,  6.,  8., 10.]]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.chunk(E, 2,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  0.,  2.,  4.],\n",
      "        [ 3.,  4.,  5.,  6.,  8., 10.]])\n",
      "tensor([[0., 1., 2.],\n",
      "        [3., 4., 5.]])\n",
      "tensor([[ 0.,  2.,  4.],\n",
      "        [ 6.,  8., 10.]])\n"
     ]
    }
   ],
   "source": [
    "print(D)\n",
    "D1, D2 = torch.chunk(D, 2, dim=1)\n",
    "print(D1)\n",
    "print(D2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  0.,  1.,  2.,  0.,  2.,  4.],\n",
      "        [ 4.,  3.,  4.,  5.,  6.,  8., 10.]])\n",
      "tensor([[1., 0., 1.],\n",
      "        [4., 3., 4.]])\n",
      "tensor([[2., 0., 2.],\n",
      "        [5., 6., 8.]])\n",
      "tensor([[ 4.],\n",
      "        [10.]])\n"
     ]
    }
   ],
   "source": [
    "print(E)\n",
    "E1, E2, E3 = torch.chunk(E, 3 ,dim=1)\n",
    "print(E1)\n",
    "print(E2)\n",
    "print(E3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.,  1.,  2.,  0.,  2.,  4.],\n",
      "        [ 3.,  4.,  5.,  6.,  8., 10.]])\n",
      "tensor([[0.],\n",
      "        [3.]])\n",
      "tensor([[1., 2.],\n",
      "        [4., 5.]])\n",
      "tensor([[ 0.,  2.,  4.],\n",
      "        [ 6.,  8., 10.]])\n"
     ]
    }
   ],
   "source": [
    "print(D)\n",
    "D1,D2,D3 =torch.split(D, [1,2,3], dim=1)\n",
    "print(D1)\n",
    "print(D2)\n",
    "print(D3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 张量计算"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 比较大小"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "A = torch.tensor([10.0])\n",
    "B = torch.tensor([10.1])\n",
    "print(torch.allclose(A, B, rtol=1e-05,atol=1e-08, equal_nan=False))\n",
    "print(torch.allclose(A, B, rtol=0.1,atol=0.01, equal_nan=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "A = torch.tensor(float(\"nan\"))\n",
    "print(torch.allclose(A, A, equal_nan=False))\n",
    "print(torch.allclose(A, A, equal_nan=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True, True, True, True, True])\n",
      "tensor([[True, True, True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "# 计算元素是否相等\n",
    "A = torch.tensor([1,2,3,4,5,6])\n",
    "B = torch.arange(1,7)\n",
    "C = torch.unsqueeze(B, dim=0)\n",
    "print(torch.eq(A, B))\n",
    "print(torch.eq(A, C))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# 判断两个张量是否具有相同的尺寸和元素\n",
    "print(torch.equal(A,B))\n",
    "print(torch.equal(A,C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True, True, True, True, True])\n",
      "tensor([[True, True, True, True, True, True]])\n"
     ]
    }
   ],
   "source": [
    "# 逐元素比较大于等于\n",
    "print(torch.ge(A,B))\n",
    "print(torch.ge(A,C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False, False, False, False, False, False])\n",
      "tensor([[False, False, False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "# 逐元素比较大于\n",
    "print(torch.gt(A,B))\n",
    "print(torch.gt(A,C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([True, True, True, True, True, True])\n",
      "tensor([[False, False, False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "# 逐元素比较小于等于\n",
    "print(torch.le(A,B))\n",
    "print(torch.lt(A,C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([False, False, False, False, False, False])\n",
      "tensor([[False, False, False, False, False, False]])\n"
     ]
    }
   ],
   "source": [
    "# 逐元素比较不等于\n",
    "print(torch.ne(A,B))\n",
    "print(torch.ne(A,C))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([False, False,  True, False])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.isnan(torch.tensor([0,1,float('nan'),2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 基本运算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: tensor([[0., 1., 2.],\n",
      "        [3., 4., 5.]])\n",
      "B: tensor([[10., 12., 14.],\n",
      "        [16., 18., 20.]])\n",
      "tensor([[  0.,  12.,  28.],\n",
      "        [ 48.,  72., 100.]])\n",
      "tensor([[0.0000, 0.0833, 0.1429],\n",
      "        [0.1875, 0.2222, 0.2500]])\n"
     ]
    }
   ],
   "source": [
    "## 矩阵逐元素相乘\n",
    "A = torch.arange(6.0).reshape(2,3)\n",
    "B = torch.linspace(10,20,steps=6).reshape(2,3)\n",
    "print(\"A:\", A)\n",
    "print(\"B:\", B)\n",
    "print(A*B)\n",
    "print(A/B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[10., 13., 16.],\n",
      "        [19., 22., 25.]])\n",
      "tensor([[-10., -11., -12.],\n",
      "        [-13., -14., -15.]])\n",
      "tensor([[inf, 12.,  7.],\n",
      "        [ 5.,  4.,  4.]])\n"
     ]
    }
   ],
   "source": [
    "print(A+B)# 逐元素加\n",
    "print(A-B) # 逐元素减\n",
    "print(B//A) # 逐元素整除"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[  0.,   1.,   8.],\n",
      "        [ 27.,  64., 125.]])\n",
      "tensor([[  0.,   1.,   8.],\n",
      "        [ 27.,  64., 125.]])\n"
     ]
    }
   ],
   "source": [
    "print(torch.pow(A, 3))\n",
    "print(A ** 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 2.],\n",
      "        [3., 4., 5.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[  1.0000,   2.7183,   7.3891],\n",
       "        [ 20.0855,  54.5982, 148.4132]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(A)\n",
    "# 张量的指数\n",
    "torch.exp(A)\n",
    "# e0.0=1.0\n",
    "# e1.0≈2.71828\n",
    "# e2.0≈7.38906\n",
    "# e3.0≈20.08554\n",
    "# e4.0≈54.59815\n",
    "# e5.0≈148.41316"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  -inf, 0.0000, 0.6931],\n",
       "        [1.0986, 1.3863, 1.6094]])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 张量的对数\n",
    "torch.log(A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 1.0000, 1.4142],\n",
      "        [1.7321, 2.0000, 2.2361]])\n",
      "tensor([[0.0000, 1.0000, 1.4142],\n",
      "        [1.7321, 2.0000, 2.2361]])\n"
     ]
    }
   ],
   "source": [
    "# 张量的平方根\n",
    "print(torch.sqrt(A))\n",
    "print(A ** 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   inf, 1.0000, 0.7071],\n",
      "        [0.5774, 0.5000, 0.4472]])\n",
      "tensor([[   inf, 1.0000, 0.7071],\n",
      "        [0.5774, 0.5000, 0.4472]])\n"
     ]
    }
   ],
   "source": [
    "# 张量的平方根倒数\n",
    "print(torch.rsqrt(A))\n",
    "print(1 / (A ** 0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1., 2.],\n",
       "        [3., 4., 4.]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 张量的数据剪裁\n",
    "torch.clamp_max(A, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3., 3.],\n",
       "        [3., 4., 5.]])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 张量的数据剪裁\n",
    "torch.clamp_min(A,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2.5000, 2.5000, 2.5000],\n",
       "        [3.0000, 4.0000, 4.0000]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 张量的数据剪裁\n",
    "torch.clamp(A, 2.5, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 2.],\n",
      "        [3., 4., 5.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0., 3.],\n",
       "        [1., 4.],\n",
       "        [2., 5.]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(A)\n",
    "## 矩阵的转置\n",
    "C = torch.t(A)\n",
    "C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5., 14.],\n",
       "        [14., 50.]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 矩阵云散，矩阵相乘， A的行数要等于C的列数\n",
    "A.matmul(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 10.,  13.],\n",
       "         [ 28.,  40.]],\n",
       "\n",
       "        [[172., 193.],\n",
       "         [244., 274.]]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = torch.arange(12.0).reshape(2,2,3)\n",
    "B = torch.arange(12.0).reshape(2,3,2)\n",
    "AB = torch.matmul(A,B)\n",
    "AB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[True, True],\n",
      "        [True, True]])\n",
      "tensor([[True, True],\n",
      "        [True, True]])\n"
     ]
    }
   ],
   "source": [
    "## 矩阵相乘之计算最后面的两个维度的乘法\n",
    "print(AB[0].eq(torch.matmul(A[0], B[0])))\n",
    "print(AB[1].eq(torch.matmul(A[1], B[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5276, 0.7621, 0.4403],\n",
      "        [0.3083, 0.1194, 0.8924],\n",
      "        [0.7664, 0.1085, 0.7034]])\n",
      "tensor([[-0.0395, -1.5086,  1.9388],\n",
      "        [ 1.4433,  0.1040, -1.0354],\n",
      "        [-0.1795,  1.6277, -0.5311]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000e+00, 3.5760e-08, 6.1513e-08],\n",
       "        [7.4419e-09, 1.0000e+00, 6.1006e-09],\n",
       "        [1.4901e-08, 0.0000e+00, 1.0000e+00]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 矩阵的逆\n",
    "C = torch.rand(3,3)\n",
    "print(C)\n",
    "D = torch.inverse(C)\n",
    "print(D)\n",
    "torch.mm(C,D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(12.)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 计算张量矩阵的迹，对角线元素的和\n",
    "torch.trace(torch.arange(9.0).reshape(3,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 统计相关的计算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
